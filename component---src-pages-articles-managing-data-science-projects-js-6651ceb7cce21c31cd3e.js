webpackJsonp([0x8923b509b85c],{205:function(e,t,a){"use strict";function n(e){return e&&e.__esModule?e:{default:e}}t.__esModule=!0;var o=a(2),i=n(o);t.default=function(){return i.default.createElement("div",null,i.default.createElement("h2",null,"Managing data science projects"),i.default.createElement("p",null,"It can be hard to know how to run data science projects and what to expect, especially if you don’t have a lead or executive data scientist in your team. I’m often the first data scientist my clients have worked with, so as well as discussing how data science fits with their business in general I find it helpful to share a framework for how to manage a data project. There are normally four stages: discovery, research, production and ongoing operation. I’ll give examples of the outcomes and timelines of each stage on a small four-month project."),i.default.createElement("p",null,"Perhaps the first point to consider is that complete data science projects can take months. As well as preparing the foundations, gathering data and building understanding, the work itself is technically complex and demands careful attention. A large company like eBay or Stitch Fix might dedicate a team of twenty data scientists to a single area for many years, but for smaller project you could go from idea to implementation in three to six months."),i.default.createElement("h3",null,"Discovery"),i.default.createElement("p",null,"Projects start by proposing ideas and sanity checking them. Some news stories you may have read about what can be done with data science are accurate, but many are hyperbolic and don’t help you think clearly about what’s possible. Involving a data scientist from the start will let you test the feasibility of ideas and give a sense of the costs, time and chance of success. They can also suggest different ideas or approaches to a business challenge you might not have considered."),i.default.createElement("p",null,"Data science is inherently risky. Even if a similar company with similar data has shipped a similar feature, that’s no guarantee it’ll work for you, or work as well for you as it did for them. That said, some features are a natural fit for data science and are probably going to work. If a user needs to schedule an email send and you have records of send times and open rates, it’s hard to imagine how even basic data-driven decision support can’t improve on whatever untested rule of thumb they’re currently using. It’s a smart, low risk feature to build."),i.default.createElement("p",null,"You’ll also want to decide what the final output from the data science project should be, perhaps a new customer facing product feature or an internal research and advisory report. Bridging product design and data science, it can help to consider how different versions of a feature could be deployed depending on the level of accuracy that can be achieved in the research stage. There may be a minimum accuracy required to make a feature viable at all. Many features can be designed in a way that improves their accuracy over time, so you may like to consider what this will make possible for the product and business in the future."),i.default.createElement("p",null,i.default.createElement("strong",null,"Outcomes:")," A shortlist of possible features, and a single feature to focus on. A sense of what the finished feature would look like if it was working well."),i.default.createElement("p",null,i.default.createElement("strong",null,"Risks:")," Discovering it’s not possible to build your feature, or that it would be prohibitively expensive."),i.default.createElement("p",null,i.default.createElement("strong",null,"Time:")," From a few days to a few weeks, usually a week."),i.default.createElement("h3",null,"Research"),i.default.createElement("p",null,"When a feature and goal has been defined, research is needed to work out exactly how to create it. This involves considering what the feature does, for example, predicting sale prices from photos of shoes, and finding ways to express that as a scientific or machine learning problem. Scientific problems can be tackled in different ways, so you might start with a shortlist of methods and considering the tradeoffs between them."),i.default.createElement("p",null,"Naturally, these methods all require data. How much data you need depends on the methods being used, with requirements ranging from tens or low hundreds to hundreds of millions of records. Often simply having more data available will improve results, so if you don’t already have much data collected it can be worth finding new ways to capture it. Approaches include adding “data exhausts” to existing processes in your product, buying third party data sets, adding different but related proxy data to your own, or creating new synthetic data."),i.default.createElement("p",null,"Sometimes it can help to add more detail to data, especially if it wasn’t captured with data science or machine learning in mind. Running a data enrichment process with your team is good for building small data sets or for enrichment that requires expert knowledge. Third party services like Amazon’s Mechanical Turk or Clickworker can be used for larger volumes."),i.default.createElement("p",null,"When the data is ready and the approach is clear it’s best to start by trying a simple technique and measuring the results. To prevent the research from becoming siloed or opaque, the work needs to be communicated, but explaining it is not always straightforward. Instead of a single measure of accuracy, there’s usually several factors which have to be traded off against each other. The technique may be complex and hard to describe, especially if the business needs to understand all of its workings and details."),i.default.createElement("p",null,"Like any project, it’s best to communicate it in the right ways to different audiences in your company. General team and company-wide presentations and discussions can build buy in and engagement in the project, and don’t usually need to go into all of the factors that underpin an accuracy measure. Bringing key stakeholders and experts into the details is usually invaluable for surfacing business insights and requirements that can shape the direction of the research and keep it on track."),i.default.createElement("p",null,"The scientific method involves rounds of trial and error, revision and improvement. Progress can be uneven, alternating between plateaus of testing new approaches with no apparent change followed by rapid improvements when a new method bears fruit. Over time there should be a gradual increase in accuracy and performance as the approach is being refined, but it’s important to know that there’s no guarantee that research will be able to deliver the results required in a reasonable timeframe or cost. These risks should have been considered in the discovery stage, you might like to set a total research budget and stop if this is reached or if interim results are good enough. Usually it’s best to take on projects where you’re at least reasonably confident the research is likely to bear fruit, or the risks and costs are clearly understood and you want to invest in experiments."),i.default.createElement("p",null,i.default.createElement("strong",null,"Outcomes:")," A data science methodology that produces the outputs you need at the accuracy level you need. You and your team understand the general approach and any important trade-offs being made."),i.default.createElement("p",null,i.default.createElement("strong",null,"Risks:")," Not achieving a minimum accuracy goal within the research time or budget. Discovering an approach that can’t be scaled to a production system."),i.default.createElement("p",null,i.default.createElement("strong",null,"Time:")," From a few weeks to a few months, usually a month."),i.default.createElement("h3",null,"Production"),i.default.createElement("p",null,"The data preparation and data science techniques are now ready to be moved into production. This is the most straightforward part of the process. Software engineering is not trivial or without its own risks, but the work of building and shipping features is not unique to data science, and the risks and requirements are well known. Sometimes you’re working with especially large amounts of data, low latency requirements, or needing to be able to cope with particularly complex data transformations. But most of the challenges you meet here have well known solutions."),i.default.createElement("p",null,"That said, there’s no single common approach for moving data science from research into production, nor is there a widely adopted production framework. Ruby on Rails transformed web development and became something close to an industry standard, React and Redux are doing something similar for front-end development. But data science only has some proprietary third-party services and nothing open source or widely adopted... yet."),i.default.createElement("p",null,"Most projects have similar processes: some kind of extract, transform and load (ETL) data pipeline that moves data from your product to a data science service and prepares it for use, model building and validation, deployment of models to a live system and ongoing monitoring. These can become complex but they’re not hard to build or tailor to different products or deployment environments. There are excellent libraries like Keras, Tensorflow, Pandas, scikit-learn and NumPy for the most common and critical tasks, used and sponsored by companies like Bloomberg, Spotify and Booking.com."),i.default.createElement("p",null,"You rarely need dedicated “big data” tools like Hadoop and Spark, and when they are needed they can often be contained to small parts of a system. AWS and Google Cloud have excellent services for working with data at scale and are straightforward to integrate with most existing technology stacks. Usually this stage needs some help from your engineering, DevOps or SRE team to ensure it’s built and deployed in a way that works well with the rest of your systems."),i.default.createElement("p",null,i.default.createElement("strong",null,"Outcome:")," A data product feature deployed to production."),i.default.createElement("p",null,i.default.createElement("strong",null,"Risk:")," Usual engineering risks of time and budget overruns. Producing complex software that’s difficult to maintain."),i.default.createElement("p",null,i.default.createElement("strong",null,"Time:")," About two months."),i.default.createElement("h3",null,"Operation"),i.default.createElement("p",null,"It’s important to monitor that features are operating properly in production. Data science systems can usually be connected to monitoring services used in other parts of a technology stack, so uptime and system status can be overseen as usual. It’s best to involve DevOps or SRE in this as with any other technology deployment. If a production system wasn’t built with the involvement of an engineering team it may take a few weeks to bring the team up to speed on it and fully handover it’s operation. Ideally the engineering team are involved throughout the build so the handover is more of a formality with no unknowns or changes required."),i.default.createElement("p",null,"Depending on what the system does it might be informative or necessary to monitor data science specific metrics like model performance and accuracy, to ensure a system that worked on test data is working well in a live setting. You might want alerts and a fallback system to kick in if performance goes outside of an expected range."),i.default.createElement("p",null,"Some machine learning models will require updating when the underlying data changes. A process for monitoring and retraining models can be incorporated into the design, build and ongoing operation of the system. It might be possible to automatically retrain models with only minimal oversight or intervention, which could be handed over to a general developer or analyst. More complex or bespoke models might need a dedicated data scientist to monitor and adjust them for normal use."),i.default.createElement("p",null,"As well as the technical and operational handover, it’s vital that the new feature is understood and adopted by its stakeholders, including product users and any internal teams. Bringing data science into a company is a transformational process, and new ways of working and thinking have to take root for it to be successful. Here’s where involving the wider team in the research efforts and building shared understanding pays dividends, as they’ll be using and championing the system for most of its life."),i.default.createElement("p",null,i.default.createElement("strong",null,"Outcomes:")," Ownership is transferred to in house technical team, reliability and adoption is assured. Adoption of the new feature and any new ways of working it requires."),i.default.createElement("p",null,i.default.createElement("strong",null,"Risk:")," Failing to maintain the feature or make full use of it. Organizational rejection of the new feature."),i.default.createElement("p",null,i.default.createElement("strong",null,"Time:")," Ongoing throughout the project, especially in the earlier stages, plus usually a few weeks dedicated handover time at the end."),i.default.createElement("h3",null,"Summing up"),i.default.createElement("p",null,"Although projects can seem daunting at first, most work falls into clear stages. Discovery and research stages are all about finding good ideas to try and figuring out what’s possible with what you have. If data science isn’t going to work for you, you want to know that as quickly as possible, and definitely before committing resources to building and managing new technology."),i.default.createElement("p",null,"If the research shows you have a viable feature, then getting it to an optimal level of performance and making decisions with the team about the best trade-offs become key tasks. Much of the delivery and ongoing operational work is similar to any other engineering project but may require ongoing data science work to support it."))},e.exports=t.default}});
//# sourceMappingURL=component---src-pages-articles-managing-data-science-projects-js-6651ceb7cce21c31cd3e.js.map