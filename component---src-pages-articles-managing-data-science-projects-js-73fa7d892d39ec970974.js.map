{"version":3,"sources":["webpack:///component---src-pages-articles-managing-data-science-projects-js-73fa7d892d39ec970974.js","webpack:///./src/pages/articles/managing-data-science-projects.js"],"names":["webpackJsonp","204","module","exports","__webpack_require__","_interopRequireDefault","obj","__esModule","default","_react","_react2","createElement"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,EAASC,GAEhC,YAQA,SAASC,GAAuBC,GAAO,MAAOA,IAAOA,EAAIC,WAAaD,GAAQE,QAASF,GANvFH,EAAQI,YAAa,CCPtB,IAAAE,GAAAL,EAAA,GDWKM,EAAUL,EAAuBI,EAIrCN,GAAQK,QCbM,iBAEdE,GAAAF,QAAAG,cAAA,WAEAD,EAAAF,QAAAG,cAAA,4CAEAD,EAAAF,QAAAG,cAAA,6iBAEAD,EAAAF,QAAAG,cAAA,8oBANA,KAM0oBD,EAAAF,QAAAG,cAAA,uBAE1oBD,EAAAF,QAAAG,cAAA,oaAEAD,EAAAF,QAAAG,cAAA,0jBAEAD,EAAAF,QAAAG,cAAA,yMAEAD,EAAAF,QAAAG,cAAA,6pBAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,2BAAH,sJAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,wBAAH,sGAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,uBAAH,oDAGAD,EAAAF,QAAAG,cAAA,sBAEAD,EAAAF,QAAAG,cAAA,gZAEAD,EAAAF,QAAAG,cAAA,yjBAEAD,EAAAF,QAAAG,cAAA,oWAEAD,EAAAF,QAAAG,cAAA,8tBAEAD,EAAAF,QAAAG,cAAA,isBAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,2BAAH,6LAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,wBAAH,4GAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,uBAAH,uDAGAD,EAAAF,QAAAG,cAAA,wBAEAD,EAAAF,QAAAG,cAAA,ycAEAD,EAAAF,QAAAG,cAAA,yUAEAD,EAAAF,QAAAG,cAAA,ukBAEAD,EAAAF,QAAAG,cAAA,6dAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,0BAAH,mDAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,wBAAH,2DAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,uBAAH,sBAGAD,EAAAF,QAAAG,cAAA,uBAEAD,EAAAF,QAAAG,cAAA,6oBAEAD,EAAAF,QAAAG,cAAA,0VAEAD,EAAAF,QAAAG,cAAA,gfAEAD,EAAAF,QAAAG,cAAA,ugBAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,2BAAH,mKAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,wBAAH,yGAEAD,EAAAF,QAAAG,cAAA,SAAGD,EAAAF,QAAAG,cAAA,uBAAH,mIAGAD,EAAAF,QAAAG,cAAA,wBAEAD,EAAAF,QAAAG,cAAA,wYAEAD,EAAAF,QAAAG,cAAA,yVDkMAT,EAAOC,QAAUA,EAAiB","file":"component---src-pages-articles-managing-data-science-projects-js-73fa7d892d39ec970974.js","sourcesContent":["webpackJsonp([150786454173788],{\n\n/***/ 204:\n/***/ (function(module, exports, __webpack_require__) {\n\n\t\"use strict\";\n\t\n\texports.__esModule = true;\n\t\n\tvar _react = __webpack_require__(4);\n\t\n\tvar _react2 = _interopRequireDefault(_react);\n\t\n\tfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\t\n\texports.default = function () {\n\t\treturn _react2.default.createElement(\n\t\t\t\"div\",\n\t\t\tnull,\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h1\",\n\t\t\t\tnull,\n\t\t\t\t\"Managing data science projects\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"It can be hard to know where to start with a data science project, especially if you don\\u2019t have a lead or executive data scientist in your team. I\\u2019m often the first data scientist my clients have worked with, so as well as discussing how data science fits with their business in general I find it helpful to share a framework for how to manage a data project. I usually work through four stages: discovery, research, production and ongoing operation. I\\u2019ll give examples of the outcomes and timelines of each stage on a small four-month project.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Perhaps the first point to consider is that data science projects can take months. As well as preparing the foundations, gathering data and building understanding, the work itself is technically complex and demands close attention. I typically quote from three to nine months for my projects, but in a large company like eBay or Stitch Fix you might see a team of twenty data scientists working on a single area for many years. I\\u2019m the person to call if you\\u2019re new to data science, and it\\u2019s important you have a successful first project that leaves you with a concrete outcome and ready to hire a permanent team. Let me show you how I do it.\"\n\t\t\t),\n\t\t\t\"  \",\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h2\",\n\t\t\t\tnull,\n\t\t\t\t\"Discovery\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"We\\u2019ll start by exploring new data feature ideas and sanity checking them. Some news stories you may have read about what can be done with data science are accurate, but many are hyperbolic and don\\u2019t help you think clearly about what\\u2019s possible. I can advise on the feasibility of ideas and give a sense of the costs, time and chance of success. And I can suggest some new ones you might not have considered.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Data science is inherently risky. Even if a similar company with similar data has shipped a similar feature, that\\u2019s no guarantee it\\u2019ll work for you, or work as well for you as it did for them. That said, some features are a natural fit for data science and are probably going to work. If a user needs to schedule an email send and you have records of send times and open rates, it\\u2019s hard to imagine how even basic data-driven decision support can\\u2019t improve on whatever untested rule of thumb they\\u2019re currently using. It\\u2019s a smart, low risk feature to build.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"We\\u2019ll talk about risk again later. At the discovery stage I want to help by sharing new ideas you might not have considered and helping you shortlist those that are in the right ballpark. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"We also need to decide what the final output from the data science project will be. In my work that\\u2019s usually a customer facing product feature or an internal research and advisory report. Bridging product design and data science, we might want to consider how different versions of a feature could be deployed depending on the level of accuracy that can be achieved in the research stage. Many features can be designed in a way that improves their accuracy over time, and we might want to think about what this would make possible for the product and business in the future. There may also be a minimum accuracy required to make the feature viable at all.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Outcomes:\"\n\t\t\t\t),\n\t\t\t\t\" A shortlist of possible features, and a single feature to focus on. A sense of what the finished feature would look like if it was working well. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Risks:\"\n\t\t\t\t),\n\t\t\t\t\" Discovering it\\u2019s not possible to build your feature, or that it would be prohibitively expensive.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Time:\"\n\t\t\t\t),\n\t\t\t\t\" From a few days to a few weeks, usually a week.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h2\",\n\t\t\t\tnull,\n\t\t\t\t\"Research\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"When we have a feature and goal defined, I\\u2019ll look into the details of how to create it. This involves considering what the feature does, for example, predicting sale prices from photos of shoes, and finding ways to express that as a scientific problem. Scientific problems can be tackled in different ways, so I might make a shortlist of methods and explain the tradeoffs between them. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Naturally, these methods all require data. How much data you need depends on the methods being used, with requirements ranging from tens or low hundreds to hundreds of millions of records. Often simply having more data available will improve results, so if you don\\u2019t already have data stored I can suggest new ways to capture it. For example, I might suggest adjusting how your product works and adding \\u201Cdata exhausts\\u201D to existing processes, buying third party data sets, adding different but related proxy data to your own, or creating new synthetic data.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Sometimes it can help to add more detail to data, especially if it wasn\\u2019t captured with data science or machine learning in mind. I can run a data enrichment process with your team, good for building small data sets or for enrichment that requires expert knowledge, or we can use a third party like Amazon\\u2019s Mechanical Turk for larger volumes.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"When the data is ready and the approach is clear I\\u2019ll usually start by trying a simple technique. This sets a baseline for accuracy and gives some results to start thinking about. Explaining the results is not always straightforward. Instead of a single measure of accuracy, there\\u2019s usually several factors which have to be traded off against each other. To prevent the research or data project from seeming mysterious and opaque, these might need to be shared in different ways to different groups in your company. Sharing updates with presentations and discussions throughout the research can build buy in and engagement in the project, letting everyone contribute insights that can shape the direction of the research.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"The scientific method involves rounds of trial and error, revision and improvement. Progress can be uneven, alternating between plateaus of testing new approaches with no apparent change followed by rapid improvements when a new method bears fruit. Over time there should be a gradual increase in accuracy and performance, but it\\u2019s important to know that there\\u2019s no guarantee that research will be able to deliver the results required in a reasonable timeframe or cost. We\\u2019ll have considered the risks in the discovery stage. Usually I take on projects where I\\u2019m very confident that research is likely to bear fruit, or you understand the risks clearly and want to try something experimental.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Outcomes:\"\n\t\t\t\t),\n\t\t\t\t\" A data science methodology that produces the outputs you need at the accuracy level you need. You and your team understand the general approach and any important trade-offs being made.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Risks:\"\n\t\t\t\t),\n\t\t\t\t\" Discovering that it\\u2019s not possible to produce a result with the time and budget available for research.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Time:\"\n\t\t\t\t),\n\t\t\t\t\" From a few weeks to a few months, usually a month.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h2\",\n\t\t\t\tnull,\n\t\t\t\t\"Production\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"The working data preparation and data science techniques are now ready to be moved into production. This is the most straightforward part of the process, it\\u2019s mostly ordinary engineering with ordinary risks and challenges. Sometimes you\\u2019re dealing with large amounts of data, low latency requirements, or needing to be able to cope with particularly complex data transformations. Most of the challenges you meet here have well known solutions. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"That said, there\\u2019s no single common approach for moving data science from research into production, nor is there a widely adopted production framework. Web development has Ruby on Rails, front end development has React and Redux, data science has\\u2026 some proprietary third-party services and nothing open source, yet. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Most projects have similar processes: some kind of extract, transform and load (ETL) data pipeline that moves data from your product to a data science service and prepares it for use, model building and validation, deployment of models to a live system and ongoing monitoring. These can become complex but they\\u2019re not hard to build or tailor to different products or deployment environments. There are excellent libraries like Pandas, scikit-learn and NumPy for the most common and critical tasks, used and sponsored by companies like Bloomberg, Spotify and Booking.com.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"You rarely need dedicated \\u201Cbig data\\u201D tools like Hadoop and Spark, and when you do need them you can often contain them to small parts of a system. AWS and Google Cloud have excellent services for working with data at scale and are straightforward to integrate with most existing technology stacks. Usually this stage needs some help from your engineering, DevOps or SRE team to ensure it\\u2019s built and deployed in a way that works well with the rest of your systems.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Outcome:\"\n\t\t\t\t),\n\t\t\t\t\" A data product feature deployed to production.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Risks:\"\n\t\t\t\t),\n\t\t\t\t\" Ordinary engineering risks of time or budget overruns.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Time:\"\n\t\t\t\t),\n\t\t\t\t\" About two months.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h2\",\n\t\t\t\tnull,\n\t\t\t\t\"Operation\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"We need to be sure that the new feature is operating properly in production. Data science systems can usually hook into the monitoring services used in other parts of a technology stack, so uptime and system status can be monitored as usual. It\\u2019s best to involve DevOps or SRE in this as with any other technology deployment. If a production system wasn\\u2019t built with the involvement of an engineering team it may take a few weeks to bring the team up to speed on it and fully handover it\\u2019s operation. Ideally the engineering team are involved throughout the build so the handover is more of a formality with no unknowns or changes required.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Depending on what the system does it might be informative or necessary to monitor data science specific metrics like model performance and accuracy, to ensure a system that worked on test data is working well in a live setting. You might want alerts and a fallback system to kick in if performance goes outside of an expected range. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Some machine learning models will require updating when the underlying data changes. A process for monitoring and retraining models can be incorporated into the design, build and ongoing operation of the system. It might be possible to automatically retrain models with only minimal oversight or intervention, which could be handed over to a general developer or analyst. More complex or bespoke models might need a dedicated data scientist to monitor and adjust them for normal use.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"As well as the technical and operational handover, it\\u2019s vital that the new feature is understood and adopted by its stakeholders, including product users and any internal teams. Bringing data science into a company is a transformational process, and new ways of working and thinking have to take root for it to be successful. Here\\u2019s where involving the wider team in the research efforts and building shared understanding pays dividends, as they\\u2019ll be using and championing the system for most of its life.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Outcomes:\"\n\t\t\t\t),\n\t\t\t\t\" Ownership is transferred to in house technical team, reliability and adoption is assured. Adoption of the new feature and any new ways of working it requires.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Risks:\"\n\t\t\t\t),\n\t\t\t\t\" Failure to maintain the feature or make full use of it. Organizational rejection of the new feature.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t_react2.default.createElement(\n\t\t\t\t\t\"strong\",\n\t\t\t\t\tnull,\n\t\t\t\t\t\"Time:\"\n\t\t\t\t),\n\t\t\t\t\" Ongoing throughout the project, especially in the earlier stages, plus usually a few weeks dedicated handover time at the end.\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"h2\",\n\t\t\t\tnull,\n\t\t\t\t\"Summing up\"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"Although projects can seem daunting at first, most work falls into clear stages. Discovery and research stages are all about finding good ideas to try and figuring out what\\u2019s possible with what you have. If data science isn\\u2019t going to work for you, you want to know that as quickly as possible, and definitely before committing resources to building and managing new technology. \"\n\t\t\t),\n\t\t\t_react2.default.createElement(\n\t\t\t\t\"p\",\n\t\t\t\tnull,\n\t\t\t\t\"If the research shows you have a viable feature, then getting it to an optimal level of performance and making decisions with the team about the best trade-offs become key tasks. Much of the delivery and ongoing operational work is similar to any other engineering project, but may require ongoing data science work to support it.\"\n\t\t\t)\n\t\t);\n\t};\n\t\n\tmodule.exports = exports[\"default\"];\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// component---src-pages-articles-managing-data-science-projects-js-73fa7d892d39ec970974.js","import React from \"react\";\n\nexport default () => (\n\n\t<div>\n\n\t<h1>Managing data science projects</h1>\n\n\t<p>It can be hard to know where to start with a data science project, especially if you don’t have a lead or executive data scientist in your team. I’m often the first data scientist my clients have worked with, so as well as discussing how data science fits with their business in general I find it helpful to share a framework for how to manage a data project. I usually work through four stages: discovery, research, production and ongoing operation. I’ll give examples of the outcomes and timelines of each stage on a small four-month project.</p>\n\n\t<p>Perhaps the first point to consider is that data science projects can take months. As well as preparing the foundations, gathering data and building understanding, the work itself is technically complex and demands close attention. I typically quote from three to nine months for my projects, but in a large company like eBay or Stitch Fix you might see a team of twenty data scientists working on a single area for many years. I’m the person to call if you’re new to data science, and it’s important you have a successful first project that leaves you with a concrete outcome and ready to hire a permanent team. Let me show you how I do it.</p>  <h2>Discovery</h2>\n\n\t<p>We’ll start by exploring new data feature ideas and sanity checking them. Some news stories you may have read about what can be done with data science are accurate, but many are hyperbolic and don’t help you think clearly about what’s possible. I can advise on the feasibility of ideas and give a sense of the costs, time and chance of success. And I can suggest some new ones you might not have considered.</p>\n\n\t<p>Data science is inherently risky. Even if a similar company with similar data has shipped a similar feature, that’s no guarantee it’ll work for you, or work as well for you as it did for them. That said, some features are a natural fit for data science and are probably going to work. If a user needs to schedule an email send and you have records of send times and open rates, it’s hard to imagine how even basic data-driven decision support can’t improve on whatever untested rule of thumb they’re currently using. It’s a smart, low risk feature to build.</p>\n\n\t<p>We’ll talk about risk again later. At the discovery stage I want to help by sharing new ideas you might not have considered and helping you shortlist those that are in the right ballpark. </p>\n\n\t<p>We also need to decide what the final output from the data science project will be. In my work that’s usually a customer facing product feature or an internal research and advisory report. Bridging product design and data science, we might want to consider how different versions of a feature could be deployed depending on the level of accuracy that can be achieved in the research stage. Many features can be designed in a way that improves their accuracy over time, and we might want to think about what this would make possible for the product and business in the future. There may also be a minimum accuracy required to make the feature viable at all.</p>\n\n\t<p><strong>Outcomes:</strong> A shortlist of possible features, and a single feature to focus on. A sense of what the finished feature would look like if it was working well. </p>\n\n\t<p><strong>Risks:</strong> Discovering it’s not possible to build your feature, or that it would be prohibitively expensive.</p>\n\n\t<p><strong>Time:</strong> From a few days to a few weeks, usually a week.</p>\n\n\n\t<h2>Research</h2>\n\n\t<p>When we have a feature and goal defined, I’ll look into the details of how to create it. This involves considering what the feature does, for example, predicting sale prices from photos of shoes, and finding ways to express that as a scientific problem. Scientific problems can be tackled in different ways, so I might make a shortlist of methods and explain the tradeoffs between them. </p>\n\n\t<p>Naturally, these methods all require data. How much data you need depends on the methods being used, with requirements ranging from tens or low hundreds to hundreds of millions of records. Often simply having more data available will improve results, so if you don’t already have data stored I can suggest new ways to capture it. For example, I might suggest adjusting how your product works and adding “data exhausts” to existing processes, buying third party data sets, adding different but related proxy data to your own, or creating new synthetic data.</p>\n\n\t<p>Sometimes it can help to add more detail to data, especially if it wasn’t captured with data science or machine learning in mind. I can run a data enrichment process with your team, good for building small data sets or for enrichment that requires expert knowledge, or we can use a third party like Amazon’s Mechanical Turk for larger volumes.</p>\n\n\t<p>When the data is ready and the approach is clear I’ll usually start by trying a simple technique. This sets a baseline for accuracy and gives some results to start thinking about. Explaining the results is not always straightforward. Instead of a single measure of accuracy, there’s usually several factors which have to be traded off against each other. To prevent the research or data project from seeming mysterious and opaque, these might need to be shared in different ways to different groups in your company. Sharing updates with presentations and discussions throughout the research can build buy in and engagement in the project, letting everyone contribute insights that can shape the direction of the research.</p>\n\n\t<p>The scientific method involves rounds of trial and error, revision and improvement. Progress can be uneven, alternating between plateaus of testing new approaches with no apparent change followed by rapid improvements when a new method bears fruit. Over time there should be a gradual increase in accuracy and performance, but it’s important to know that there’s no guarantee that research will be able to deliver the results required in a reasonable timeframe or cost. We’ll have considered the risks in the discovery stage. Usually I take on projects where I’m very confident that research is likely to bear fruit, or you understand the risks clearly and want to try something experimental.</p>\n\n\t<p><strong>Outcomes:</strong> A data science methodology that produces the outputs you need at the accuracy level you need. You and your team understand the general approach and any important trade-offs being made.</p>\n\n\t<p><strong>Risks:</strong> Discovering that it’s not possible to produce a result with the time and budget available for research.</p>\n\n\t<p><strong>Time:</strong> From a few weeks to a few months, usually a month.</p>\n\n\n\t<h2>Production</h2>\n\n\t<p>The working data preparation and data science techniques are now ready to be moved into production. This is the most straightforward part of the process, it’s mostly ordinary engineering with ordinary risks and challenges. Sometimes you’re dealing with large amounts of data, low latency requirements, or needing to be able to cope with particularly complex data transformations. Most of the challenges you meet here have well known solutions. </p>\n\n\t<p>That said, there’s no single common approach for moving data science from research into production, nor is there a widely adopted production framework. Web development has Ruby on Rails, front end development has React and Redux, data science has… some proprietary third-party services and nothing open source, yet. </p>\n\n\t<p>Most projects have similar processes: some kind of extract, transform and load (ETL) data pipeline that moves data from your product to a data science service and prepares it for use, model building and validation, deployment of models to a live system and ongoing monitoring. These can become complex but they’re not hard to build or tailor to different products or deployment environments. There are excellent libraries like Pandas, scikit-learn and NumPy for the most common and critical tasks, used and sponsored by companies like Bloomberg, Spotify and Booking.com.</p>\n\n\t<p>You rarely need dedicated “big data” tools like Hadoop and Spark, and when you do need them you can often contain them to small parts of a system. AWS and Google Cloud have excellent services for working with data at scale and are straightforward to integrate with most existing technology stacks. Usually this stage needs some help from your engineering, DevOps or SRE team to ensure it’s built and deployed in a way that works well with the rest of your systems.</p>\n\n\t<p><strong>Outcome:</strong> A data product feature deployed to production.</p>\n\n\t<p><strong>Risks:</strong> Ordinary engineering risks of time or budget overruns.</p>\n\n\t<p><strong>Time:</strong> About two months.</p>\n\n\n\t<h2>Operation</h2>\n\n\t<p>We need to be sure that the new feature is operating properly in production. Data science systems can usually hook into the monitoring services used in other parts of a technology stack, so uptime and system status can be monitored as usual. It’s best to involve DevOps or SRE in this as with any other technology deployment. If a production system wasn’t built with the involvement of an engineering team it may take a few weeks to bring the team up to speed on it and fully handover it’s operation. Ideally the engineering team are involved throughout the build so the handover is more of a formality with no unknowns or changes required.</p>\n\n\t<p>Depending on what the system does it might be informative or necessary to monitor data science specific metrics like model performance and accuracy, to ensure a system that worked on test data is working well in a live setting. You might want alerts and a fallback system to kick in if performance goes outside of an expected range. </p>\n\n\t<p>Some machine learning models will require updating when the underlying data changes. A process for monitoring and retraining models can be incorporated into the design, build and ongoing operation of the system. It might be possible to automatically retrain models with only minimal oversight or intervention, which could be handed over to a general developer or analyst. More complex or bespoke models might need a dedicated data scientist to monitor and adjust them for normal use.</p>\n\n\t<p>As well as the technical and operational handover, it’s vital that the new feature is understood and adopted by its stakeholders, including product users and any internal teams. Bringing data science into a company is a transformational process, and new ways of working and thinking have to take root for it to be successful. Here’s where involving the wider team in the research efforts and building shared understanding pays dividends, as they’ll be using and championing the system for most of its life.</p>\n\n\t<p><strong>Outcomes:</strong> Ownership is transferred to in house technical team, reliability and adoption is assured. Adoption of the new feature and any new ways of working it requires.</p>\n\n\t<p><strong>Risks:</strong> Failure to maintain the feature or make full use of it. Organizational rejection of the new feature.</p>\n\n\t<p><strong>Time:</strong> Ongoing throughout the project, especially in the earlier stages, plus usually a few weeks dedicated handover time at the end.</p>\n\n\n\t<h2>Summing up</h2>\n\n\t<p>Although projects can seem daunting at first, most work falls into clear stages. Discovery and research stages are all about finding good ideas to try and figuring out what’s possible with what you have. If data science isn’t going to work for you, you want to know that as quickly as possible, and definitely before committing resources to building and managing new technology. </p>\n\n\t<p>If the research shows you have a viable feature, then getting it to an optimal level of performance and making decisions with the team about the best trade-offs become key tasks. Much of the delivery and ongoing operational work is similar to any other engineering project, but may require ongoing data science work to support it.</p>\n\n\t</div>\n );\n\n\n// WEBPACK FOOTER //\n// ./src/pages/articles/managing-data-science-projects.js"],"sourceRoot":""}